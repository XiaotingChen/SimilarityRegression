{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Specify Parameters/Requirements/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "from similarityregression import AlignmentTools as alntools\n",
    "from similarityregression import PairwiseAlignment as pwsaln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "WorkingOn = 'DNA'\n",
    "\n",
    "loc_CurrentDB = '../CisBP/' + WorkingOn + '/'\n",
    "loc_EScoreOverlaps = loc_CurrentDB + 'Escores/ByFamily/'\n",
    "loc_DBFiles = loc_CurrentDB + '/DBFiles/'\n",
    "loc_DBDAlignments = loc_CurrentDB + 'DomainAlignments/'\n",
    "\n",
    "#Construct Alignments\n",
    "if os.path.isdir(WorkingOn + '/ConstructAlignments/') == False:\n",
    "    os.mkdir(WorkingOn + '/ConstructAlignments/')\n",
    "loc_ConstructAlignments = WorkingOn + '/ConstructAlignments/Unaligned/'\n",
    "if os.path.isdir(loc_ConstructAlignments) == False:\n",
    "    os.mkdir(loc_ConstructAlignments)\n",
    "if os.path.isdir(loc_ConstructAlignments.replace('Unaligned', 'Aligned')) == False:\n",
    "    os.mkdir(loc_ConstructAlignments.replace('Unaligned', 'Aligned'))\n",
    "    \n",
    "#Models\n",
    "loc_ModelsByFamily = WorkingOn + '/ByFamily/'\n",
    "if os.path.isdir(loc_ModelsByFamily) == False:\n",
    "    os.mkdir(loc_ModelsByFamily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read DBFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "motifs = pd.read_csv(loc_DBFiles + 'motifs.tab', sep = '\\t', skiprows=[1], index_col=0)\n",
    "motif_features = pd.read_csv(loc_DBFiles + 'motif_features.tab', sep = '\\t', skiprows=[1], index_col=0)\n",
    "domains = pd.read_csv(loc_DBFiles + 'domains.tab', sep = '\\t', skiprows=[1], index_col=0)\n",
    "tf_families = pd.read_csv(loc_DBFiles + 'tf_families.tab', sep = '\\t', skiprows=[1], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Blacklists & Replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "blacklist_BadFamilies = {\n",
    "    tf_families[tf_families['DBDs'] == 'UNKNOWN' ].index[0] : 'UNKNOWN'\n",
    "}\n",
    "\n",
    "#Filter motifs with missing data\n",
    "blacklist_motifs = set(['M00001_1.97d'])\n",
    "motifs = motifs.drop(blacklist_motifs, axis = 0)\n",
    "\n",
    "#Fill the alignment locations\n",
    "dict_DBDAlignments = {\n",
    "}\n",
    "for Domain_ID, info in domains.iterrows():\n",
    "    Pfam_Name = info['Pfam_Name']\n",
    "    #Check if muscle exists \n",
    "    dalnloc = loc_DBDAlignments + Pfam_Name + '.muscle.fa'\n",
    "    if os.path.isfile(dalnloc) == True:\n",
    "        dict_DBDAlignments[Pfam_Name] = dalnloc\n",
    "    else:\n",
    "        dict_DBDAlignments[Pfam_Name] = loc_DBDAlignments + Pfam_Name + '.hmmaln'\n",
    "        \n",
    "#\n",
    "Blacklist_Studies = set() #Set to ['Lam11', 'Barrera2016']  to remove synthetic/mutated constructs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1) Create unaligned construct sequence files\n",
    "Based on whatever constructs have E-Score Overlaps (e.g. are from PBM or RNAcompete experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! MISSING DBD/RBD Domain Info: M00001_1.97d\n"
     ]
    }
   ],
   "source": [
    "for EScoreOverlapFile in glob.glob(loc_EScoreOverlaps + '*'):\n",
    "    EScoreOverlaps = pd.read_csv(EScoreOverlapFile, sep = '\\t')\n",
    "    ID_TFFam = EScoreOverlapFile.split('/')[-1].replace('.EscoreOverlaps.txt', '')\n",
    "    \n",
    "    if ID_TFFam in blacklist_BadFamilies:\n",
    "        continue\n",
    "    \n",
    "    tf_family = tf_families.loc[ID_TFFam]\n",
    "    DBDs = tf_family['DBDs'].split(',')\n",
    "    \n",
    "    AlnDict_ByPfam = {}\n",
    "    PfamAlnLens = {}\n",
    "    \n",
    "    for DBD in DBDs:\n",
    "        AlnDict_ByPfam[DBD] = {}\n",
    "        loc_alnFile = dict_DBDAlignments[DBD]\n",
    "        if 'hmmaln' in loc_alnFile:\n",
    "            #Parse PFams for match positions\n",
    "            alnmnt, matchpos, _, _ = alntools.ParseStockholmWithMatches(loc_alnFile)\n",
    "            for record in alnmnt:\n",
    "                unaln = record.id\n",
    "                aln = str(record.seq)\n",
    "                aln_matchpos = ''\n",
    "                for i in matchpos:\n",
    "                    aln_matchpos += aln[i]\n",
    "                AlnDict_ByPfam[DBD][unaln] = aln_matchpos.upper().replace('.', '-')\n",
    "        else:\n",
    "            for unaln, aln in alntools.FastaIter(loc_alnFile):\n",
    "                AlnDict_ByPfam[DBD][unaln] = aln.upper().replace('.', '-')\n",
    "        PfamAlnLens[DBD] = len(aln)\n",
    "        \n",
    "    JointSeqDict = {}\n",
    "    for currentDBD, currentDBD_dict in AlnDict_ByPfam.items():\n",
    "        for unaln, aln in currentDBD_dict.items():\n",
    "            jointaln = ''\n",
    "            for DBD in DBDs:\n",
    "                if DBD == currentDBD:\n",
    "                    jointaln += aln\n",
    "                else:\n",
    "                    jointaln += '-'*PfamAlnLens[DBD]\n",
    "            JointSeqDict[unaln] = jointaln\n",
    "                \n",
    "    \n",
    "    MIDs = set(list(EScoreOverlaps['MID_x']) + list(EScoreOverlaps['MID_y']))\n",
    "    with open(loc_ConstructAlignments + ID_TFFam + '.txt', 'w') as outf:\n",
    "        for MID in MIDs:\n",
    "            alnseqs = []\n",
    "            if MID in motif_features['Motif_ID'].values:\n",
    "                MID_mfeats = motif_features[motif_features['Motif_ID'] == MID]\n",
    "                for ID_mfeat, mfeat in MID_mfeats.iterrows():\n",
    "                    unaln = mfeat['MotifFeature_Sequence']\n",
    "                    aln = JointSeqDict[unaln]\n",
    "                    alnseqs.append(aln)\n",
    "                joinedseq = ','.join(alnseqs)\n",
    "                outf.write('\\t'.join([MID, joinedseq]) + '\\n')\n",
    "            else:\n",
    "                print '! MISSING DBD/RBD Domain Info:', MID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2) Align constructs with pairwise DBD/RBD alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA/ConstructAlignments/Unaligned/F002_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F007_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F009_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F024_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F026_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F028_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F039_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F050_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F082_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F088_1.97d.txt\n",
      "DNA/ConstructAlignments/Unaligned/F091_1.97d.txt\n"
     ]
    }
   ],
   "source": [
    "for loc_ConstructAlignment in glob.glob(loc_ConstructAlignments + '*'):\n",
    "    print loc_ConstructAlignment\n",
    "    \n",
    "    loc_AlnJSON = loc_ConstructAlignment.replace('Unaligned', 'Aligned')\n",
    "    \n",
    "    #Get Escore Info\n",
    "    Family_ID = loc_ConstructAlignment.split('/')[-1].replace('.txt','')\n",
    "    EScoreOverlapFile = loc_EScoreOverlaps + Family_ID + '.EscoreOverlaps.txt'\n",
    "    EScoreOverlaps = pd.read_csv(EScoreOverlapFile, sep = '\\t', index_col=[0,3]) \n",
    "    \n",
    "    #Read construct sequnences\n",
    "    UnalnDict = {}\n",
    "    with open(loc_ConstructAlignment, 'r') as infile:\n",
    "        for line in infile:\n",
    "            ID, unaln = line.strip().split('\\t')\n",
    "            unaln = unaln.split(',')\n",
    "            UnalnDict[ID] = unaln\n",
    "    IDs = UnalnDict.keys()\n",
    "    IDs.sort()\n",
    "    \n",
    "    #Loop through all pairs of constructs\n",
    "    with gzip.open(loc_AlnJSON + '.gz', 'w') as outfile:\n",
    "        for x, y in itertools.combinations(IDs, 2):\n",
    "            o = pwsaln.AlignDBDArrays((x, UnalnDict[x]), (y, UnalnDict[y]), ByPosNorm = 'L')\n",
    "            o['EScoreOverlap'] = EScoreOverlaps.loc[(x, y), 'EScoreOverlap']\n",
    "            o['EClass'] = EScoreOverlaps.loc[(x, y), 'EClass']\n",
    "            o['Study'] = list(EScoreOverlaps.loc[(x, y), ['Study_x', 'Study_y']])\n",
    "            \n",
    "            outfile.write('\\t'.join([str((x, y)), json.dumps(o)]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3) Create training dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for loc_AlnJSON in glob.glob(loc_ConstructAlignments.replace('Unaligned', 'Aligned') + '*'):\n",
    "    FID = loc_AlnJSON.split('/')[-1].replace('.txt', '')\n",
    "    print 'Parsing for R:', FID\n",
    "    \n",
    "    #Open Outputs (and make folders if necessary)\n",
    "    loc_OutputFiles = loc_ModelsByFamily + FID\n",
    "    if os.path.isdir(loc_OutputFiles) == False:\n",
    "        os.mkdir(loc_OutputFiles)\n",
    "    loc_OutputFiles += '/TrainingData/'\n",
    "    if os.path.isdir(loc_OutputFiles) == False:\n",
    "        os.mkdir(loc_OutputFiles)\n",
    "       \n",
    "    Y_Sims_PctID = gzip.open(loc_OutputFiles + 'Y_Sims_PctID.csv.gz', 'w')\n",
    "    X_PctID = gzip.open(loc_OutputFiles + 'X_PctID.csv.gz','w')\n",
    "    X_AvgB62 = gzip.open(loc_OutputFiles + 'X_AvgB62.csv.gz', 'w')\n",
    "    X_PctID_Smooth3 = gzip.open(loc_OutputFiles + 'X_PctID_Smooth3.csv.gz', 'w')\n",
    "    X_AvgB62_Smooth3 = gzip.open(loc_OutputFiles + 'X_AvgB62_Smooth3.csv.gz', 'w')\n",
    "    \n",
    "    #Loop through alignment info\n",
    "    count = 0\n",
    "    uIDs = set()\n",
    "    IDs = []\n",
    "    with gzip.open(loc_AlnJSON, 'r') as infile:\n",
    "        for line in infile:\n",
    "            count += 1\n",
    "            ID, aln = line.strip().split('\\t')\n",
    "            \n",
    "            ID = eval(ID)\n",
    "            IDs.append(ID)\n",
    "            uIDs.add(ID[0])\n",
    "            uIDs.add(ID[1])\n",
    "            \n",
    "            aln = json.loads(aln)\n",
    "            \n",
    "            #Check if Escores are null\n",
    "            if (pd.isnull(aln['EScoreOverlap'])) or (len(Blacklist_Studies.intersection(aln['Study'])) > 0):\n",
    "                continue\n",
    "                \n",
    "            #Check if Excluded studies are in o\n",
    "                \n",
    "            #1) Parse the Y-info\n",
    "            if count == 1:\n",
    "                h = ['MID_x', 'MID_y', 'EScoreOverlap', 'EClass','PctID_L', 'PctID_S', 'ArrayLenDifference', 'MultiAlnFlag']\n",
    "                Y_Sims_PctID.write(','.join(h) + '\\n')\n",
    "            oline = list(ID) \n",
    "            for col in ['EScoreOverlap', 'EClass','PctID_L', 'PctID_S', 'ArrayLenDifference', 'MultiAlnFlag']:\n",
    "                oline.append(aln[col])\n",
    "            Y_Sims_PctID.write(','.join(map(str, oline)) + '\\n')\n",
    "            \n",
    "            #2) Parse the X matrices\n",
    "            for filehandle, dictID in zip([X_PctID, X_AvgB62, X_PctID_Smooth3, X_AvgB62_Smooth3], \n",
    "                                      ['ByPos.PctID', 'ByPos.AvgB62', 'ByPos.PctID.Smooth3', 'ByPos.AvgB62.Smooth3']):\n",
    "                if count == 1:\n",
    "                    h = ['MID_x', 'MID_y'] + ['p' + str(x + 1) for x in range(len(aln['ByPos.PctID']))]\n",
    "                    filehandle.write(','.join(h) + '\\n')\n",
    "                oline = list(ID) + map(str, aln[dictID])\n",
    "                filehandle.write(','.join(oline) + '\\n')\n",
    "                \n",
    "    #Close Files\n",
    "    for x in [X_PctID, X_AvgB62, X_PctID_Smooth3, X_AvgB62_Smooth3, Y_Sims_PctID]:\n",
    "        x.close()\n",
    "\n",
    "    #Calculate Testing folds\n",
    "    count = 0\n",
    "    with open(loc_OutputFiles + 'CVTestIndicies_i0.txt', 'w') as outf:\n",
    "        for uID in uIDs:\n",
    "            present_0 = []\n",
    "            count += 1\n",
    "            for i, ID in enumerate(IDs):\n",
    "                if uID in ID:\n",
    "                    present_0.append(i)\n",
    "            oline = [uID] + present_0\n",
    "            outf.write('\\t'.join(map(str, oline)) + '\\n')\n",
    "        #print count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
