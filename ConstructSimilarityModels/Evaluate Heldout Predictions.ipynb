{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "\n",
    "from similarityregression import PairwiseAlignment as pwsaln\n",
    "from similarityregression import PredictSimilarity as srpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate SR Models on new PBM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: F002_1.97d (NO_THRESHOLD)\n",
      "Working on: F009_1.97d\n",
      "Working on: F026_1.97d\n",
      "Working on: F039_1.97d\n",
      "Working on: F082_1.97d\n",
      "Working on: F088_1.97d (NO_THRESHOLD)\n",
      "Working on: F091_1.97d\n",
      "Working on: F135_1.97d\n",
      "Working on: F140_1.97d (NO_THRESHOLD)\n",
      "Working on: F141_1.97d (NO_THRESHOLD)\n",
      "Working on: F158_1.97d (NO_THRESHOLD)\n",
      "Working on: F169_1.97d (NO_THRESHOLD)\n",
      "Working on: F170_1.97d\n",
      "Working on: F173_1.97d\n",
      "Working on: F174_1.97d\n",
      "Working on: F196_1.97d\n",
      "Working on: F201_1.97d\n",
      "Working on: F223_1.97d\n",
      "Working on: F231_1.97d\n",
      "Working on: F238_1.97d\n",
      "Working on: F251_1.97d\n",
      "Working on: F266_1.97d\n",
      "Working on: F273_1.97d\n",
      "Working on: F278_1.97d\n",
      "Working on: F281_1.97d (NO_THRESHOLD)\n",
      "Working on: F282_1.97d\n",
      "Working on: F291_1.97d (NO_THRESHOLD)\n",
      "Working on: F293_1.97d (NO_THRESHOLD)\n",
      "Working on: F296_1.97d (NO_THRESHOLD)\n",
      "Working on: F301_1.97d\n",
      "Working on: F310_1.97d (NO_THRESHOLD)\n",
      "Working on: F314_1.97d\n",
      "Working on: F315_1.97d\n",
      "Working on: F317_1.97d (NO_THRESHOLD)\n",
      "Working on: F323_1.97d\n",
      "Working on: F324_1.97d\n"
     ]
    }
   ],
   "source": [
    "CMs = {}\n",
    "Running_Truth = []\n",
    "Running_Preds = []\n",
    "\n",
    "OmitTrainingConstructs = False\n",
    "\n",
    "for loc_heldout_Y in glob.glob('DNA/ByFamily/*/TrainingData/Heldout.Y_Sims_PctID.csv.gz'):\n",
    "    FID = loc_heldout_Y.split('/')[2]\n",
    "    #Check if model was built\n",
    "    if os.path.isfile('DNA/SRModels/' + FID + '.json'):\n",
    "        fSRModel = srpred.ReadSRModel('DNA/SRModels/' + FID + '.json')\n",
    "        print 'Working on:', FID\n",
    "    else:\n",
    "        fSRModel = srpred.ReadSRModel('DNA/SRModels/NO_THRESHOLD.json')\n",
    "        print 'Working on:', FID, '(NO_THRESHOLD)'\n",
    "        \n",
    "    heldout_Y = pd.read_csv(loc_heldout_Y, index_col=[0,1])\n",
    "    if OmitTrainingConstructs:\n",
    "        TrainingConstructs = set()\n",
    "        with open(loc_heldout_Y.replace('Heldout.Y_Sims_PctID.csv.gz', 'CVTestIndicies_i0.txt')) as cvfile:\n",
    "            for line in cvfile:\n",
    "                line = line.strip().split('\\t')\n",
    "                TrainingConstructs.add(line[0])\n",
    "        #Get rid of comparisons w/ TrainingConstructs\n",
    "        keeprows = [False]*heldout_Y.shape[0]\n",
    "        for c, i in enumerate(list(heldout_Y.index)):\n",
    "            if len(TrainingConstructs.intersection(i)) == 0:\n",
    "                keeprows[c] = True\n",
    "        heldout_Y = heldout_Y.loc[keeprows,]\n",
    "    if fSRModel['Model.Class'] == 'SimilarityRegression':\n",
    "        heldout_X = pd.read_csv('DNA/ByFamily/' + FID + '/TrainingData/Heldout.X_' + fSRModel['SR.Features']  + '.csv.gz', index_col=[0,1])\n",
    "        heldout_X = heldout_X.loc[heldout_Y.index,]\n",
    "        #Score w/ python\n",
    "        Scores = []\n",
    "        for i, x in heldout_X.iterrows():\n",
    "            f = (x - fSRModel['SR.FeatureScales.mean'])/fSRModel['SR.FeatureScales.sd']\n",
    "            f[np.isnan(f)] = 0\n",
    "            score = fSRModel['SR.Intercept'] + np.dot(fSRModel['SR.Weights'], f)\n",
    "            if fSRModel['SR.LogisticTransform'] == True:\n",
    "                score = srpred.logistic(score)\n",
    "            Scores.append(score)\n",
    "        heldout_Y['SRScores'] = Scores\n",
    "    else:\n",
    "        heldout_Y['SRScores'] = heldout_Y[fSRModel['Model.Name']]\n",
    "    \n",
    "    heldout_Y = heldout_Y[heldout_Y['EClass'].isnull() == False] #For some of the NO_THRESHOLD families\n",
    "    if heldout_Y.shape[0] > 0:\n",
    "        #Evaluate Predictions\n",
    "        heldout_Y['Class'] = 'Amb'\n",
    "        heldout_Y.loc[heldout_Y['EClass'] == 1,'Class'] = 'HSim'\n",
    "        heldout_Y.loc[heldout_Y['EScoreOverlap'] < 0.2,'Class'] = 'Dis'\n",
    "\n",
    "        heldout_Y['Pred'] = 'Amb'\n",
    "        heldout_Y.loc[heldout_Y['SRScores'] > fSRModel['Threshold.HSim'] ,'Pred'] = 'HSim'\n",
    "        heldout_Y.loc[heldout_Y['SRScores'] < fSRModel['Threshold.Dis'] ,'Pred'] = 'Dis'\n",
    "\n",
    "        CM = confusion_matrix(heldout_Y['Class'], heldout_Y['Pred'], labels=[\"HSim\", \"Amb\", \"Dis\"])\n",
    "        CMs[FID] = CM\n",
    "        Running_Truth += list(heldout_Y['Class'])\n",
    "        Running_Preds += list(heldout_Y['Pred'])\n",
    "        \n",
    "        heldout_Y['SR.Name'] = fSRModel['Model.Class']\n",
    "        heldout_Y.to_csv('HeldoutScores/' + FID + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  898  1338   140]\n",
      " [  122  5480  1042]\n",
      " [   94 20553 24546]]\n",
      "PERFORMANCE BY CLASS\n",
      "HSim       | Precision: 0.806104129264 Recall: 0.377946127946\n",
      "Amb        | Precision: 0.200211903109 Recall: 0.824804334738\n",
      "Dissimilar | Precision: 0.954057835821 Recall: 0.543137211515\n",
      "COMMON METRICS\n",
      "Matthews Correlation Coefficient (MCC): 0.289570033574\n",
      "F1: 0.570416689724\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for FID, cm in CMs.items():\n",
    "    if count == 0:\n",
    "        HPreds = cm.copy()\n",
    "    else:\n",
    "        HPreds += cm\n",
    "    count += 1\n",
    "    \n",
    "print HPreds\n",
    "print 'PERFORMANCE BY CLASS'\n",
    "print 'HSim       | Precision:', 1.0*HPreds[0,0]/sum(HPreds[:,0]), 'Recall:', 1.0*HPreds[0,0]/sum(HPreds[0,:])\n",
    "print 'Amb        | Precision:', 1.0*HPreds[1,1]/sum(HPreds[:,1]), 'Recall:', 1.0*HPreds[1,1]/sum(HPreds[1,:])\n",
    "print 'Dissimilar | Precision:', 1.0*HPreds[2,2]/sum(HPreds[:,2]), 'Recall:', 1.0*HPreds[2,2]/sum(HPreds[2,:])\n",
    "print 'COMMON METRICS'\n",
    "print 'Matthews Correlation Coefficient (MCC):', matthews_corrcoef(Running_Truth, Running_Preds) \n",
    "print 'F1:', f1_score(Running_Truth, Running_Preds, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CM_DF = pd.DataFrame(HPreds,\n",
    "             index = ['Highly Similar', 'Ambiguous', 'Dissimilar'], \n",
    "             columns=['Highly Similar', 'Ambiguous', 'Dissimilar'])\n",
    "CM_DF.to_csv('ConfusionMatrix_HeldoutPreds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate heldout TFs in-traning NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for loc_heldout in glob.glob('HeldoutScores/*'):\n",
    "    FID = loc_heldout.split('/')[-1].replace('.csv','')\n",
    "    heldout_Y = pd.read_csv(loc_heldout)\n",
    "    AllConstructs = set(list(heldout_Y['MID_x']) + list(heldout_Y['MID_y']))\n",
    "    TrainingConstructs = set()\n",
    "    with open('DNA/ByFamily/%s/TrainingData/CVTestIndicies_i0.txt'%FID) as cvfile:\n",
    "        for line in cvfile:\n",
    "            line = line.strip().split('\\t')\n",
    "            TrainingConstructs.add(line[0])\n",
    "    HeldoutConstructs = AllConstructs.difference(TrainingConstructs)\n",
    "    NNs = []\n",
    "    for HeldoutConstruct in HeldoutConstructs:\n",
    "        HeldoutConstruct_Comps = heldout_Y[(heldout_Y['MID_x'] == HeldoutConstruct) | (heldout_Y['MID_y'] == HeldoutConstruct)].copy()\n",
    "        HeldoutConstruct_Comps = HeldoutConstruct_Comps.sort_values('SRScores', ascending=False)\n",
    "        NNs.append( HeldoutConstruct_Comps.index[0] )\n",
    "    NNs = list(set(NNs))\n",
    "    NNs.sort() \n",
    "    NNs = heldout_Y.loc[NNs].copy()\n",
    "    NNs['Family_ID'] = FID\n",
    "    \n",
    "    if count == 0:\n",
    "        heldout_NN = NNs.copy()\n",
    "    else:\n",
    "        heldout_NN = pd.concat([heldout_NN, NNs])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: F170_1.97d\n",
      "Working on: F091_1.97d\n",
      "Working on: F315_1.97d\n",
      "Working on: F223_1.97d\n",
      "Working on: F141_1.97d (NO_THRESHOLD)\n",
      "Working on: F082_1.97d\n",
      "Working on: F039_1.97d\n",
      "Working on: F158_1.97d (NO_THRESHOLD)\n",
      "Working on: F273_1.97d\n",
      "Working on: F278_1.97d\n",
      "Working on: F026_1.97d\n",
      "Working on: F238_1.97d\n",
      "Working on: F196_1.97d\n",
      "Working on: F231_1.97d\n",
      "Working on: F251_1.97d\n",
      "Working on: F310_1.97d (NO_THRESHOLD)\n",
      "Working on: F169_1.97d (NO_THRESHOLD)\n",
      "Working on: F281_1.97d (NO_THRESHOLD)\n",
      "Working on: F009_1.97d\n",
      "Working on: F296_1.97d (NO_THRESHOLD)\n",
      "Working on: F323_1.97d\n",
      "Working on: F266_1.97d\n",
      "Working on: F282_1.97d\n",
      "Working on: F174_1.97d\n",
      "Working on: F293_1.97d (NO_THRESHOLD)\n",
      "Working on: F201_1.97d\n",
      "Working on: F173_1.97d\n",
      "Working on: F301_1.97d\n",
      "Working on: F314_1.97d\n",
      "Working on: F324_1.97d\n",
      "Working on: F135_1.97d\n"
     ]
    }
   ],
   "source": [
    "fams = pd.read_csv('../CisBP/DNA/DBFiles/tf_families.tab', index_col=0, delimiter='\\t')\n",
    "heldout_NN['Family_Name'] = [fams['Family_Name'].get(x) for x in heldout_NN['Family_ID']]\n",
    "heldout_NN.to_csv('../Figures/FigureSX_HeldoutNNEscore/HeldoutNNs.csv', index = False)\n",
    "\n",
    "#Parse Out Thresholds\n",
    "Thresh = []\n",
    "for FID in set(heldout_NN['Family_ID']):\n",
    "    if os.path.isfile('DNA/SRModels/' + FID + '.json'):\n",
    "        fSRModel = srpred.ReadSRModel('DNA/SRModels/' + FID + '.json')\n",
    "        print 'Working on:', FID\n",
    "        o = [fSRModel['Family_ID'], fSRModel['Family_Name'], fSRModel['Threshold.HSim'],  fSRModel['Threshold.Dis']]\n",
    "    else:\n",
    "        fSRModel = srpred.ReadSRModel('DNA/SRModels/NO_THRESHOLD.json')\n",
    "        print 'Working on:', FID, '(NO_THRESHOLD)'\n",
    "        o = [FID, fams.loc[FID, 'Family_Name'], fSRModel['Threshold.HSim'],  fSRModel['Threshold.Dis']]\n",
    "    Thresh.append(o)\n",
    "Thresh = pd.DataFrame(Thresh, columns = ['FID', 'Family_Name', 'HSim', 'Dis'])\n",
    "Thresh.to_csv('../Figures/FigureSX_HeldoutNNEscore/ModelThresholds.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
